name: Polynote with Spark and Hadoop

on:
  workflow_dispatch:
    inputs:
      polynote_version:
        description: "Polynote version"
        required: true
        default: "0.4.4"
      scala_version:
        description: "Scala version"
        required: true
        default: "2.12"
      jdk_version:
        description: "JDK version"
        required: true
        default: "11"
      spark_version:
        description: "Spark version"
        required: true
        default: "3.2.0"
      hadoop_version:
        description: "Hadoop version"
        required: true
        default: "3.3.1"

jobs:
  publish_docker:
    name: "Build ghcr.io/khwj/khwj/data-platform-containers/polynote:${{ github.event.inputs.polynote_version }}-scala${{ github.event.inputs.scala_version }}-jdk${{ github.event.inputs.jdk_version }}-hadoop${{ github.event.inputs.hadoop_version }}"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v1
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Build and push
        id: docker_build
        uses: docker/build-push-action@v2
        with:
          context: ./polynote
          file: ./polynote/Dockerfile.spark
          build-args: |
            "POLYNOTE_IMAGE"=ghcr.io/khwj/data-platform-containers/polynote:${{ github.event.inputs.polynote_version }}-scala${{ github.event.inputs.scala_version }}-jdk${{ github.event.inputs.jdk_version }}
            "SPARK_IMAGE"=ghcr.io/khwj/data-platform-containers/spark:${{ github.event.inputs.spark_version }}-hive2.3.9-scala{{ github.event.inputs.scala_version }}-jdk${{ github.event.inputs.jdk_version }}-hadoop${{ github.event.inputs.hadoop_version }}
          tags: ghcr.io/khwj/data-platform-containers/polynote:${{ github.event.inputs.polynote_version }}-scala${{ github.event.inputs.scala_version }}-jdk${{ github.event.inputs.jdk_version }}-spark${{ github.event.inputs.spark_version }}-hadoop${{ github.event.inputs.hadoop_version }}
          push: true
